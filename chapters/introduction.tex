\section{The Space Environment}
Surrounding the Earth there exists a sparse gas of ions and electrons called a \emph{plasma}. These particles reside in a state of constant flux, resulting from a tenuous and dynamic balance of energy fluxes -- streaming in from the sun, and back and forth within the Earth's terrestrial atmosphere. Every human-made satellite has passed through it; the vast majority of satellites, with the exception of deep-space probes, live out their entire existence within it. Aside from the lunar astronauts of the Apollo era, every single human in space has spent the duration of their journey within this constantly-evolving cloud of matter. The technology ubiquitous in our day-to-day lives -- instant international communication, satellite-aided global positioning systems -- all require signals to be transmitted through it. We call this region, from say, an altitude of 100 km on out to the moon, the \emph{Space Environment}.

%The space environment is defined largely by the Earth's magnetic field. We refer to this system as the \emph{Magnetosphere}, and the plasma contained within it as the \emph{Plasmasphere}. 

The space environment is largely defined by the Earth's magnetic field, which serves to constrain plasma to a toroidal shape. The region in which the Earth's magnetic field impacts significant action is called the \emph{magnetosphere}, and the region of constrained plasma immediately surrounding the Earth the \emph{plasmasphere}. The majority of the particles within the plasmasphere are cold, with energies less than $\sim$ 1 eV. However, a sparse population of high-energy particles exist, with energies approaching 10 MeV, and velocities approaching the speed of light. These so-called `killer electrons', while sparse in number, present a significant hazard for both electrical systems, and to living organisms in space\citep{Barth2003}. The populations of these particles form two shells, known as the Van Allen radiation belts, separated by a depleted `slot' region. Understanding the behavior of these high-energy particles are key to sustained human activity in space. 

The population of high-energy particles is driven by a complex balance of sources, acceleration mechanisms, and loss processes. This thesis considers the effect of one such loss mechanism: the action of radio waves generated by terrestrial lightning through a resonant scattering process known as \emph{Lightning-induced Electron Precipitation} (LEP), and examines the regions of the space environment in which losses due to LEP may be substantial. We perform this study through extensive numerical simulation of single LEP events, under a variety of space weather conditions, and examine global trends by extrapolating over a global lightning activity dataset.

\begin{figure}[t]
\begin{center}
\includegraphics[draft]{figures/space_environment.png}

\caption[Diagram of the various regions of the space environment]{Write me pls}
\label{fig:space_environment}
\end{center}
\end{figure}

\section{Motivation}
\subsection{The Radiation Belts}
The Van Allen radiation belts, first measured in 1958 by \cite{VanAllen1958} on the Explorer I and III satellites, represent one of the earliest major discoveries of the American space program. The belts are an enhancement in very-high-energy particles (E $>$ 100 keV), which extend from 1.2 to 7 earth radii along the equator, and follow the Earth's magnetic field to $\sim \pm65^\circ$ latitude \citep{Walt1994}. While the location and population of the belts are highly dynamic, it is customary to divide the population of high-energy particles into two toroidal shells: an inner belt below $\sim$ 3 Earth radii; an outer belt between $\sim$ 3 and 7 Earth radii; and a `slot' depletion region between 2 and 3 Earth radii. The radiation belts are dominantly populated by electrons ($e^-$) and Hydrogen ions ($H^+$). Geomagnetically-trapped particles are confined by the Earth's magnetic field, and exhibit a helical bouncing motion, reflecting between fixed points near the northern and southern poles.

It was recognized early on that the ionizing effects of high-energy electrons represented a hazard for both humans and electronics in space. The Apollo manned spaceflight missions dealt with the risk of ionizing radiation both by incorporating additional aluminum shielding, and by designing their orbit trajectory to minimize time spent in the Van Allen belts \citep{Apollo1973}. Astronauts aboard the International Space Station wear passive dosimeters to measure total exposure; furthermore, the ISS includes radiation-safe regions which are better-shielded to the space environment, for use in cases of extreme solar or geomagnetic activity \citep{ugh}. 

As silicon gate sizes continue to shrink, electronics have become increasingly susceptible to radiation-related failures. Single-event upsets (SEU) can occur when a high-energy particle impinges on a volatile memory circuit, imparting enough energy to erroneously change a bit from 0 to 1, or 1 to 0. The effects of SEU can be mitigated through specialized design practices, including triple-redundant systems and larger gate sizes, and are regarded as `soft' failures from which a system can be designed to survive. Of additional risk are catastrophic failure events -- for instance, in which an energetic particle can impinge on the oxide layer of a FET transistor, and create an electrical short, either temporary or permanent. Such an event can render spaceborne electronics useless.

\subsection{Sources and Loss Processes}
The radiation belts are generally populated by the stream of particles arriving from the solar wind, which provides a steady flow of cold electrons (velocities $\sim 300$ km/sec, and temperatures $\sim 10^{-5}$ Kelvin) \citep{Montgomery1974, Tascione1988}. These particles are then gradually accelerated to relativistic energies through a variety of acceleration processes within the magnetosphere, (itself a very open research topic) such as resonant interactions with ULF waves, chorus waves, and magnetotail processes \citep{Shprits2006,  Bortnik2007a, Thorne2013}.

The dynamics of the radiation belts are marked with periodic filling events, in which the distribution of high-energy particles rapidly increase \cite{Baker2014}. In the absence of other interactions, these particles would remain trapped by the Earth's magnetic field, and populations would continue to increase indefinitely. However the influx of new particles is balanced by an equally-complex set of loss processes.

Throughout the 1960s and 1970s, a wealth of research was performed on the lifetime of energetic radiation belt particles, most notably through a series of atmospheric nuclear experiments known as the \emph{Starfish} project\footnotemark. Starfish was a 1.4 megaton nuclear device, detonated 400 km above Johnson Island on July 9, 1962, which provided an artificial, local enhancement to the inner radiation belt, at approx 1.2 Earth radii \citep{Hess1963}. Data from particle detectors aboard several early satellites (Telstar, Injun, Ariel, and Tracc) were then used to study the lifetime of energetic protons and electrons. Starfish electrons were found to be very long-lived, with lifetimes on the order of $\sim 2$ years \citep{Beall1967}. In the months following the Starfish detonation, seven satellites, (including Telstar 1, the first commercial communications satellite, launched one day after the Starfish detonation) experienced catastrophic failures \citep{Wenaas1978, Barth2003, Conrad2010}, inspiring a decades-long research interest in the lifetime of radiation belt particles, and anthropogenic techniques for the mitigation of nuclear-injected particles.

The earliest loss-mechanism theories considered Compton scattering against the nucleii of atmospheric neutral constituents \citep{Walt1964}. This model showed reasonable agreement with Starfish particles at the lowest altitudes ($\sim$ 1.1 Earth radii), but greatly overestimated particle lifetimes for the majority of inner-belt electrons, indicating that other, unaccounted-for loss processes must be present. 
\footnotetext[1]{While the Starfish detonation was the greatest yield and highest-altitude, and thus of the greatest interest in radiation belt physics, it was not by far an isolated event. Between 1955 and 1962, with a lapse following an international armistice between 1958 and 1961, the United States performed twelve atmospheric nuclear tests, at altitudes ranging from 6 to 540 kilometers, with yields in the kiloton range, reaching a maximum with Starfish at 1.4 megatons. Simultaneously, between 1961 and 1962, the Soviet Union performed five high-altitude detonations between 1.2 and 300 kilotons. An international moratorium on high-altitude detonations took place in 1963 with the High Altitude Nuclear Test Ban Treaty \citep{Hess1964b, Schwelb1964, Hoerlin1976, Norris1996}.}


\section{Previous Work}
% PUT IN AN ASIDE ABOUT LIGHTNING AND VLF HERE -- You'll need to talk about the guided portion, etc etc

\subsection{Wave-Particle Interactions}
Recognizing the need for additional loss mechanisms, It was soon theorized that resonant interactions with radio waves could significantly alter the reflection height of trapped particles, and in turn drive these particles further into the neutral atmosphere, where they stood a much higher chance of colliding with neutral constituents, and eventually precipitating into the neutral atmosphere. Unlike in free space, the charged medium of the plasmasphere allows propagation of only certain frequencies and modes of radio wave (see section \ref{section:dispersion_relations}). Right-hand, circularly-polarized waves in the VLF band ($\sim < 30 $ kHz) are common in the plasmasphere, and arise from a variety of generation mechanisms. These waves are known as \emph{whistlers}, named for the descending, whistle-like tones originating from distant, broadband impulses. Terrestrial lightning is a persistent source of whistlers, with $\sim$ 50 flashes/sec occurring globally; each whistler can propagate through the magnetosphere and persist for several seconds. Within literature, whistler waves are often divided into two categories: ``ducted'' waves, which follow temporary enhancements in plasma density, with wavenormal vectors nearly parallel to the background magnetic field, and ``magnetospherically reflecting'' whistlers, which are not constrained to a duct, and generally have a much more-oblique wavenormal angle.

Figure \ref{fig:whistlers} shows an example of a whistler wave and its causative lightning stroke. Whistler waves can also be generated naturally within the plasmasphere (\emph{chorus} and \emph{hiss}) or be induced via high energy, ground-based VLF transmitters \citep{Graf2013}. (It should be noted that whistlers are not the only category of waves relevant to the radiation belts -- see the review paper by \cite{Thorne2010a} for an overview of various other waves).

\begin{figure}[t]
\begin{center}
\includegraphics[draft]{figures/whistlers.png}

\caption[An example of a lightning-generated whistler wave]{Write me pls}
\label{fig:whistlers}
\end{center}
\end{figure}

The concept of lightning as a loss mechanism for radiation belt electrons was first proposed by \cite{Dungey1963}, and subsequently by \cite{Cornwall1964}, through resonant interactions with whistler-mode waves. \citeauthor{Dungey1963} provided order-of-magnitude estimates for electron lifetimes, arguing for the significance of LEP in the inner radiation belt, and against for the outer radiation belt, and proposed an anthropogenic source of whistlers as a provisional loss mechanism in the event of further nuclear enhancements. 

Shortly thereafter, \cite{Kennel1966b}, and subsequently \cite{Lyons1973}, provided an alternative mathematical framework for the diffusion of radiation belt particles due to random-walk interactions with incoherent whistler mode waves known as \emph{plasmaspheric hiss}. From here, studies of wave-induced precipitation mechanisms can be grouped into two categories: coherent studies (the ``Liouville" approach), in which known particles are subjected to a known wave event, and incoherent studies (the ``Fokker-Planck'' approach), in which distributions of particles evolve through repeated, stochastic interactions with broadband radio wave activity.

\subsection{LEP measurements}
The first one-to-one measurements of precipitating electrons associated with causative whistlers were made by \cite{Voss1984}, confirming the feasibility of LEP as a radiation belt loss mechanism. However, due to the sporadic nature of LEP and the dearth of space vehicles to measure it, one-to-one measurements of LEP are somewhat rare.
LEP can be measured terrestrially across a great distance by examining the perturbations to VLF-band transmitter signals as they propagate in the waveguide formed by the Earth and the charged ionosphere. Additional charges imparted by LEP to the ionosphere can perturb this waveguide, and in turn affect the measured amplitude and phase of transmitted signals. These sporadic events (frequently known as ``Trimpi" events, a nod to their discovery by \cite{Trimpi1973}), have been studied for several decades \citep{Trimpi1973, Carpenter1984, Inan1988, Burgess1993}. These works further confirm the existence and frequency of LEP events; however due to the nature of the waveguide sensing method, it is difficult to obtain direct electron flux estimates without substantial modeling.

\subsection{Modeling of single LEP events}
A substantial history of numerical modeling of LEP exists at Stanford, beginning with the thesis work of \cite{Inan1977}, who performed numerical simulations of pitch-angle scattering due to short-duration, monochromatic, ducted whistler waves. This work was then elaborated on throughout the 1980s in a series of test-particle simulations \citep{Chang1983, Chang1985, Inan1989}, which directly simulate the effect of whistler waves on discrete collections of electrons in the time domain.

Gyrorotation-averaged equations of motion for the interaction of waves and trapped particles were derived by \cite{Bell1984}. Combining the derivations of \cite{Ristic1992}, the thesis work of \cite{Ristic1993} and subsequently \cite{Ristic1998} provided a mathematical framework for the interaction of generic whistler waves and trapped particles, and demonstrated the relative importance of oblique wave interactions. 

The thesis work and subsequent publications of \citeauthor{Lauben1998} \citep{Lauben1998, Lauben1999, Lauben2001} represented a full numerical treatment of precipitation due to a single lightning stroke, combining test-particle simulations with a numerical raytracing scheme to estimate whistler wave intensity vs. location, frequency and time. The thesis work of \cite{Bortnik2005} brought further detail to the simulation of LEP, again using a raytracing scheme, and incorporating (among others) Landau damping calculations and multiple resonant modes. The work of \citeauthor{Lauben1998} and \citeauthor{Bortnik2005} primarily differ in their treatment of the resonant interaction: \citeauthor{Lauben1998} uses a test-particle approach to track the change in particle pitch angles across long distances; \citeauthor{Bortnik2005} uses a hybrid coherent / incoherent scatter model, in which the coherent interactions of a collection of particles along a field line is considered independent from other locations and wave frequencies; the resulting resonant interaction is then summed in quadrature across all frequencies and latitudes, to provide a pseudo-incoherent, RMS scattering approximation.

The wave-particle interaction model of \cite{Bortnik2005, Bortnik2006} was then applied to narrowband, transmitter-generated waves by \cite{Kulkarni2009} to examine the efficiency of spaceborne VLF transmitters as a remediation tool for radiation belt electrons; \cite{Cotts2011} further expanded on the \citeauthor{Bortnik2005} model by incorporating the effects of atmospheric backscatter.

The work presented here in this thesis is based off of the original model from \cite{Bortnik2005}; however we provide several model improvements, including an elaborated treatment of the background plasma; a more-accurate model of variation along the longitudinal axis; and various practical code improvements.

% inan 1878, chang + inan thru the 80s, Ristic 1993, Lauben 1998, Bortnik 2005, the ABS stuff, etc
% Should we talk about incoherent methods? They're not really relevant here, but...
\subsection{Behavior of whistler waves in the magnetosphere}
The study of LEP is complex, in that it requires study of both the interaction of particles and waves, as well as the behavior of the waves and particles before and after the interaction. [Ray tracing, landau damping histories here]

\subsection{Electron lifetime estimates due to LEP}
% Abel and Thorne
% Meredeth


\section{Scientific Contribution}

\section{Thesis Organization}
This thesis is divided into the following chapters.
\begin{itemize}
\item Chapter \ref{chapter:physics} describes the background physics of the LEP process, the numerical methods used within this study, and the mathematical models of the various environments which we examine. 
\item Chapter \ref{chapter:power} presents a study of the persistent VLF radio energy within the magnetosphere, resulting from terrestrial cloud-to-ground lightning discharges. 
\item Chapter \ref{chapter:3dWIPP} provides a simulation of electron precipitation resulting from a canonical cloud-to-ground lightning discharge, and a discussion of various model improvements, notably with our treatment of the longitudinal axis. 
\item Chapter \ref{chapter:global_estimates} provides seasonal estimates of the global impact of LEP resulting from the GLD360 dataset and a reduced-complexity model. \item Chapter \ref{chapter:VPM}, admittedly a bit of a tangent, presents the design of a CubeSat-based instrumentation suite, designed for direct, \emph{in-situ} measurements of LEP by taking time-and-space-coincident measurements of electron loss cone distributions, and incident VLF waves. The design provides some interesting on-board signal processing to reduce the data bandwidth significantly, and is implemented entirely in fixed-point logic using an FPGA (and \emph{no} onboard CPU). I worked on this design in the earlier years of my time at Stanford; at time of writing it is due to be launched in early 2019.
\end{itemize}

